{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0tyIsliieNr"
   },
   "source": [
    "# Tarea 2 - Named Entity Recognition\n",
    "\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:21:15.416464Z",
     "start_time": "2020-06-22T15:21:15.411478Z"
    },
    "colab_type": "text",
    "id": "X3QUWWoWaSE3"
   },
   "source": [
    "- **Nombre:**\n",
    "Joaquin Peréz, Valentina Sepúlveda.\n",
    "- **Usuario o nombre de equipo en Codalab:** \n",
    "vsepulv, meperd0nas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iWlfabmkaSE7"
   },
   "source": [
    "### Reglas de la tarea"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T15:33:49.808401Z",
     "start_time": "2020-06-22T15:33:49.798428Z"
    },
    "colab_type": "text",
    "id": "3w9Dw4CSaSE8"
   },
   "source": [
    "Algunos detalles de la competencia:\n",
    "\n",
    "- Para que su tarea sea evaluada, deben participar en la competencia como también, enviar este notebook con su informe.\n",
    "- Para participar, deben registrarse en la competencia en Codalab en grupos de máximo 2 alumnos. Cada grupo debe tener un nombre de equipo. (¡Y deben reportarlo en su informe!)\n",
    "- Las métricas usadas serán Precisión, Recall y F1.\n",
    "- En esta tarea se recomienda usar GPU. Pueden ejecutar su tarea en colab (lo cual trae todo instalado) o pueden intentar correrlo en su computador. en este caso, deberá ser compatible con cuda y deberán instalar todo por su cuenta.\n",
    "- En total pueden hacer un **máximo de 4 envíos**.\n",
    "- Por favor, todas sus dudas haganlas en el hilo de U-cursos de la tarea. Los emails que lleguen al equipo docente serán remitidos a ese medio. Recuerden el ánimo colaborativo del curso!!\n",
    "- Estar top 5 en alguna métrica equivale a 1 punto extra en la nota final.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V5BBxJWQaSE-"
   },
   "source": [
    "**Link a la competencia:  https://competitions.codalab.org/competitions/25302?secret_key=690406c7-b3b0-4092-8694-d08d7991ca94**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4HfZqQ-_aSFE"
   },
   "source": [
    "### Reporte\n",
    "\n",
    "Este debe cumplir la siguiente estructura:\n",
    "\n",
    "1.\t**Introducción**: Presentar brevemente el problema a resolver, los modelos utilizados en el desarrollo de la tarea y conclusiones obtenidas. (0.5 Puntos)\n",
    "\n",
    "2.\t**Modelos**: Describir brevemente los modelos, métodos y hiperparámetros utilizados. (1.0 puntos)\n",
    "\n",
    "4.\t**Métricas de evaluación**: Describir las métricas utilizadas en la evaluación indicando que miden y cuál es su interpretación en este problema en particular. (0.5 puntos)\n",
    "\n",
    "5.\t**Experimentos**: Reportar todos sus experimentos y código en esta sección. Comparar los resultados obtenidos utilizando diferentes modelos. ¡Es vital haber realizado varios experimentos para sacar una buena nota! (3.0 puntos)\n",
    "\n",
    "6.\t**Conclusiones**: Discutir resultados, proponer trabajo futuro. (1.0 punto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f7X2FruyaSFG"
   },
   "source": [
    "\n",
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PzQlYlmGaSFH"
   },
   "source": [
    "## Introducción\n",
    "\n",
    "Dentro de los problemas del procesamiento del lenguaje natural, hay tres grandes categorias: *Sequence Classification*, *Sequence Labeling* y por el ultimo el *Sequence to Sequence*. El primero consiste en dado una oración ser capaz de clasificarlo en una clase discreta, ya sea por ejemplo de carga emocional positiva o negativa, o clasificarlo por el tema que trata.\n",
    "\n",
    "El segundo, *Sequence Labeling*, trata que dado una oración, clasificar cada palabra en una categoria o etiqueta, dando como resultado una sequencia de etiquetas final del mismo largo que la inicial. Y por ultimo el *Sequence to Sequence* habla de transformar una oración en otra oración pero manteniendo sus propiedades.\n",
    "\n",
    "De los tres tipos de problemas nos enfocaremos en el segundo, *Sequence Labeling*.\n",
    "De aqui hay un problema conocido: el Named Entity Recognition del cual trata este trabajo. El *Named Entity Recognition* (o NER), en español traducido como Detección de Entidades trata de ser capaz de encontrar las entidades, ya sea una Empresa, Persona u otro tipo de categoria; dentro de una oración y marcarlas dentro de este input. Así cada palabra del input tiene una etiqueta asociada que explica cual Entidad tiene si es que tiene una, o si no tiene.\n",
    "\n",
    "Para resolver este tipo de problemas se decidió resolverlos con un tipo de redes neuronales, las redes neuronales recurrentes (o RNN). Estas redes consisten en que definen sus valores actuales en base a sus valores pasados, así siendo capaz de reconstruir toda la secuencia y ser capaz de tomar en consideración el contexto al momento de clasificar.\n",
    "\n",
    "Para esto definimos tres modelos, dos basados en un tipo de arquitectura de RNN distinta, el primer modelo basado en la arquitectura LSTM, el segundo basado en la arquitectura GRU. El utlimo es sin embargo otro tipo de modelo, una red neuronal convolucional (o CNN) simple.\n",
    "\n",
    "Dados estos modelos, como resultados se obtuvo que..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kyW7lkksFlnh"
   },
   "outputs": [],
   "source": [
    "# Instalar torchtext (en codalab) - Descomentar.\n",
    "!pip3 install torchtext==0.6\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt0VcWDeFi6Q"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/Data/train_NER_esp.txt -nc # Dataset de Entrenamiento\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/Data/val_NER_esp.txt -nc    # Dataset de Validación (Para probar y ajustar el modelo)\n",
    "!wget https://github.com/dccuchile/CC6205/releases/download/Data/test_NER_esp.txt -nc  # Dataset de la Competencia. Estos datos solo contienen los tokens. ¡¡SON LOS QUE DEBEN SER PREDICHOS!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:49.795126Z",
     "start_time": "2020-06-23T22:25:49.791108Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3DcM_IjgCdzz",
    "outputId": "3f6e49ef-290a-4aeb-bdc8-aa86b3fa6003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchtext import data, datasets\n",
    "\n",
    "# Garantizar reproducibilidad \n",
    "SEED = 1234\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "# Primer Field: TEXT. Representan los tokens de la secuencia\n",
    "TEXT = data.Field(lower=False) \n",
    "\n",
    "# Segundo Field: NER_TAGS. Representan los Tags asociados a cada palabra.\n",
    "NER_TAGS = data.Field(unk_token=None)\n",
    "\n",
    "fields = ((\"text\", TEXT), (\"nertags\", NER_TAGS))\n",
    "\n",
    "train_data, valid_data, test_data = datasets.SequenceTaggingDataset.splits(\n",
    "    path=\"./\",\n",
    "    train=\"train_NER_esp.txt\",\n",
    "    validation=\"val_NER_esp.txt\",\n",
    "    test=\"test_NER_esp.txt\",\n",
    "    fields=fields,\n",
    "    encoding=\"iso-8859-1\",\n",
    "    separator=\" \"\n",
    ")\n",
    "TEXT.build_vocab(train_data)\n",
    "NER_TAGS.build_vocab(train_data)\n",
    "# Seteamos algunas variables que nos serán de utilidad mas adelante...\n",
    "UNK_IDX = TEXT.vocab.stoi[TEXT.unk_token]\n",
    "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "\n",
    "PAD_TAG_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "O_TAG_IDX = NER_TAGS.vocab.stoi['O']\n",
    "\n",
    "BATCH_SIZE = 16  # disminuir si hay problemas de ram.\n",
    "\n",
    "# Usar cuda si es que está disponible.\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "# Dividir datos entre entrenamiento y test\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device,\n",
    "    sort=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AaVhZ5iaaSFK"
   },
   "source": [
    "## Métricas de evaluación\n",
    "\n",
    "- **Precision:** Esta métrica contabiliza la cantidad de verdaderos positivos (tp) versus la cantidad de falsos positivos (fp), con la siguiente fórmula: $\\frac{tp}{tp+fp}$.\n",
    "\n",
    "- **Recall:** Esta métrica considera, a diferencia de la \"Precision\" la cantidad de verdaderos positivos versus la cantidad de falsos negativos (fn), con la siguiente fórmula: $\\frac{tp}{tp+fn}$.\n",
    "\n",
    "- **F1 score:** El F1 score es la media armónica entre la presición y el recall, es decir: $2 \\cdot \\frac{precition \\cdot recall}{precition + recall}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:51.654826Z",
     "start_time": "2020-06-23T22:25:51.103450Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "9mUOOLEWiicU"
   },
   "outputs": [],
   "source": [
    "# Definimos las métricas\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "import warnings\n",
    "import sklearn.exceptions\n",
    "warnings.filterwarnings(\"ignore\",\n",
    "                        category=sklearn.exceptions.UndefinedMetricWarning)\n",
    "\n",
    "\n",
    "def calculate_metrics(preds, y_true, pad_idx=PAD_TAG_IDX, o_idx=O_TAG_IDX):\n",
    "    \"\"\"\n",
    "    Calcula precision, recall y f1 de cada batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Obtener el indice de la clase con probabilidad mayor. (clases)\n",
    "    y_pred = preds.argmax(dim=1, keepdim=True)\n",
    "    # Obtenemos los indices distintos de 0.\n",
    "\n",
    "    # filtramos <pad> y O para calcular los scores.\n",
    "    mask = [(y_true != o_idx) & (y_true != pad_idx)]\n",
    "    y_pred = y_pred[mask]\n",
    "    y_true = y_true[mask]\n",
    "\n",
    "    # traemos a la cpu\n",
    "    y_pred = y_pred.view(-1).to('cpu')\n",
    "    y_true = y_true.to('cpu')\n",
    "    \n",
    "    # calcular scores\n",
    "    f1 = f1_score(y_true, y_pred, average='macro')\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "\n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Hod516H1aSG2"
   },
   "source": [
    "-------------------\n",
    "\n",
    "### Modelo Baseline\n",
    "\n",
    "Teniendo ya cargado los datos, toca definir nuestro modelo. Este baseline tendrá una capa de embedding, unas cuantas LSTM y una capa de salida y usará dropout en el entrenamiento.\n",
    "\n",
    "Este constará de los siguientes pasos: \n",
    "\n",
    "1. Definir la clase que contendrá la red.\n",
    "2. Definir los hiperparámetros e inicializar la red. \n",
    "3. Definir la época de entrenamiento\n",
    "3. Definir la función de loss.\n",
    "\n",
    "\n",
    "\n",
    "Recomendamos que para experimentar, encapsules los modelos en una sola variable y luego la fijes en model para entrenarla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPdlsM0PgGTo"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:54.527162Z",
     "start_time": "2020-06-23T22:25:54.518186Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "WsRuiUuHiicY"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # Por cada batch del iterador de la época:\n",
    "    for batch in iterator:\n",
    "\n",
    "        # Extraemos el texto y los tags del batch que estamos procesado\n",
    "        text = batch.text\n",
    "        tags = batch.nertags\n",
    "\n",
    "        # Reiniciamos los gradientes calculados en la iteración anterior\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Predecimos los tags del texto del batch.\n",
    "        predictions = model(text)\n",
    "\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "\n",
    "        # Reordenamos los datos para calcular la loss\n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.view(-1)\n",
    "\n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "\n",
    "        # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "        loss = criterion(predictions, tags)\n",
    "        \n",
    "        # Calculamos el accuracy\n",
    "        precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "        # Calculamos los gradientes\n",
    "        loss.backward()\n",
    "\n",
    "        # Actualizamos los parámetros de la red\n",
    "        optimizer.step()\n",
    "\n",
    "        # Actualizamos el loss y las métricas\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_precision += precision\n",
    "        epoch_recall += recall\n",
    "        epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion):\n",
    "\n",
    "    epoch_loss = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_recall = 0\n",
    "    epoch_f1 = 0\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Indicamos que ahora no guardaremos los gradientes\n",
    "    with torch.no_grad():\n",
    "        # Por cada batch\n",
    "        for batch in iterator:\n",
    "\n",
    "            text = batch.text\n",
    "            tags = batch.nertags\n",
    "\n",
    "            # Predecimos\n",
    "            predictions = model(text)\n",
    "\n",
    "            predictions = predictions.view(-1, predictions.shape[-1])\n",
    "            tags = tags.view(-1)\n",
    "\n",
    "            # Calculamos el Cross Entropy de las predicciones con respecto a las etiquetas reales\n",
    "            loss = criterion(predictions, tags)\n",
    "\n",
    "            # Calculamos las métricas\n",
    "            precision, recall, f1 = calculate_metrics(predictions, tags)\n",
    "\n",
    "            # Actualizamos el loss y las métricas\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_precision += precision\n",
    "            epoch_recall += recall\n",
    "            epoch_f1 += f1\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_precision / len(\n",
    "        iterator), epoch_recall / len(iterator), epoch_f1 / len(iterator)\n",
    "\n",
    "import time\n",
    "\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def init_weights(m):\n",
    "    # Inicializamos los pesos como aleatorios\n",
    "    for name, param in m.named_parameters():\n",
    "         nn.init.normal_(param.data, mean=0, std=0.1) \n",
    "        \n",
    "    # Seteamos como 0 los embeddings de UNK y PAD.\n",
    "    model.embedding.weight.data[UNK_IDX] = torch.zeros(EMBEDDING_DIM)\n",
    "    model.embedding.weight.data[PAD_IDX] = torch.zeros(EMBEDDING_DIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:51.666751Z",
     "start_time": "2020-06-23T22:25:51.656778Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rMPL08XqaSG3"
   },
   "outputs": [],
   "source": [
    "class GENERAL_NER_RNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout,\n",
    "                 pad_idx,\n",
    "                 rnn_type=\"LSTM\"):\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa de embedding\n",
    "        self.embedding = nn.Embedding(input_dim,\n",
    "                                      embedding_dim,\n",
    "                                      padding_idx=pad_idx)\n",
    "\n",
    "        #Capa RNN\n",
    "        #\"\"\"\n",
    "        if rnn_type is \"LSTM\":\n",
    "          self.rnn = nn.LSTM(embedding_dim,\n",
    "                        hidden_dim,\n",
    "                        num_layers=n_layers,\n",
    "                        bidirectional=bidirectional,\n",
    "                        dropout= dropout if n_layers> 1 else 0)\n",
    "        elif rnn_type is \"GRU\":\n",
    "          self.rnn = nn.GRU(embedding_dim,\n",
    "                        hidden_dim,\n",
    "                        num_layers=n_layers,\n",
    "                        bidirectional=bidirectional,\n",
    "                        dropout= dropout if n_layers> 1 else 0)      \n",
    "        #\"\"\"\n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "                            output_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Convertir lo enviado a embedding\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        outputs, (hidden) = self.rnn(embedded)\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "\n",
    "        # Pasar los embeddings por la rnn (LSTM)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        # Predecir usando la capa de salida.\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RMsvGrpmgW8x"
   },
   "outputs": [],
   "source": [
    "class GENERAL_NER_RNN_EMB(nn.Module):\n",
    "    def __init__(self,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 bidirectional,\n",
    "                 dropout,\n",
    "                 pad_idx,\n",
    "                 rnn_type=\"LSTM\"):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        # Capa de embedding\n",
    "        self.embedding = external_embedding\n",
    "        self.embedding.padding_idx = pad_idx\n",
    "        #Capa GRU\n",
    "        #\"\"\"\n",
    "        if rnn_type == \"LSTM\":\n",
    "          self.rnn = nn.LSTM(300,\n",
    "                        hidden_dim,\n",
    "                        num_layers=n_layers,\n",
    "                        bidirectional=bidirectional,\n",
    "                        dropout= dropout if n_layers> 1 else 0)\n",
    "        elif rnn_type == \"GRU\":\n",
    "          self.rnn = nn.GRU(300,\n",
    "                        hidden_dim,\n",
    "                        num_layers=n_layers,\n",
    "                        bidirectional=bidirectional,\n",
    "                        dropout= dropout if n_layers> 1 else 0)    \n",
    "        #\"\"\"\n",
    "        # Capa de salida\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "                            output_dim)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text):\n",
    "\n",
    "        #text = [sent len, batch size]\n",
    "\n",
    "        # Convertir lo enviado a embedding\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "\n",
    "        outputs, (hidden) = self.rnn(embedded)\n",
    "        #embedded = [sent len, batch size, emb dim]\n",
    "\n",
    "        # Pasar los embeddings por la rnn (LSTM)\n",
    "\n",
    "        #output = [sent len, batch size, hid dim * n directions]\n",
    "        #hidden/cell = [n layers * n directions, batch size, hid dim]\n",
    "\n",
    "        # Predecir usando la capa de salida.\n",
    "        predictions = self.fc(self.dropout(outputs))\n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "\n",
    "        return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eN5QrFv8gZiz"
   },
   "outputs": [],
   "source": [
    "# Si se mete esta vaina debería quedar bien c:\n",
    "class GENERAL_NER_CNN(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 embedding_dim,\n",
    "                 hidden_dim,\n",
    "                 output_dim,\n",
    "                 n_layers,\n",
    "                 dropout,\n",
    "                 pad_idx):\n",
    "      \n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(\n",
    "            input_dim,\n",
    "            embedding_dim,\n",
    "            padding_idx=pad_idx)\n",
    "        self.conv = nn.Conv1d(\n",
    "            in_channels=embedding_dim*input_dim,\n",
    "            out_channels=hidden_dim,\n",
    "            kernel_size=3*embedding_dim,\n",
    "            stride=embedding_dim)\n",
    "        \n",
    "        self.pool=nn.MaxPool1d(hidden_dim,stride=embedding_dim)\n",
    "        \n",
    "        self.fc=nn.Linear(hidden_dim,output_dim)\n",
    "\n",
    "        self.drop_out = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        #embedded = embedded.view(embedded.shape[0], 1, -1)\n",
    "        z =nn.ReLU(self.conv(embedded))\n",
    "        z=self.pool(z)\n",
    "        \n",
    "        z=self.fc(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfSoGgnNyTsp"
   },
   "source": [
    "## Parámetros Globales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njhbp9YaySZY"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "OUTPUT_DIM = len(NER_TAGS.vocab)  # número de clases\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lRYOEDiQaSHK"
   },
   "source": [
    "--------------------\n",
    "### Modelo 1\n",
    "\n",
    "Para el primer modelo escogimos la RNN que estaba definida como Baseline con algunas modificaciones, es decir con una red LSTM, pero cambiando los hiperparametros. Una red LSTM es una arquitectura de RNN, que se caracteriza por ser capaz de conservar los gradientes de las derivadas de las RNN, y esto\n",
    "lo realiza por un mecanismo de atención, que son unos valores que \"definen\" cual valor dentro del input, o output tiene más peso, y por lo tanto cuales valores recordar y cuales olvidar.\n",
    "\n",
    "Como primer hiperparametro se decidió tener el tamaño de las capas ocultas de la RNN, a 5 capas ocultas iniciales. Tiene dimension de Embeddings de 200, y la dimension de sus capas ocultas es de 250. Es una red bidireccional.\n",
    "\n",
    "En general este modelo tuvo como resultados...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:51.722604Z",
     "start_time": "2020-06-23T22:25:51.717615Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "c81f8ki5aSHL"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 200 # b: 200 dimensión de los embeddings. 100--> 200\n",
    "HIDDEN_DIM = 250  # b: 250 dimensión de la capas LSTM  128 --> 250\n",
    "N_LAYERS = 8  # b: 5 número de capas. 2 --> 5\n",
    "DROPOUT = 0.25 # b: 0.25 --> 0.15\n",
    "BIDIRECTIONAL = True #False --> True\n",
    "\n",
    "model=GENERAL_NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX, \"LSTM\")\n",
    "model_name=\"Modelo 1\"\n",
    "model_n_epochs = 10 # 10 --> 20\n",
    "model_loss = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "model_optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rV9oLkN1aSHO"
   },
   "source": [
    "---------------\n",
    "\n",
    "### Modelo 2\n",
    "\n",
    "Para el segundo modelo, se decidió probar con la otra arquitectura conocida de las RNN, la arquitectura GRU, con su implementacion de PyTorch. La arquitectura GRU es conocida al igual que la LSTM, y tambien sirve para el procesamiento del lenguaje. La GRU funciona de manera similar a la LSTM, definiendo un mecanismo de atención para definir cual informacion importante usar versus cual olvidar.\n",
    "\n",
    "Se decidió la dimensión de los embeddings en 300 y en dos capas ocultas. Se decide tambien definirla como una red bidireccional. Tambien se decidió en procesarlo en 5 epochs, para evitar el overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:51.728587Z",
     "start_time": "2020-06-23T22:25:51.724596Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KWPzETaNaSHP"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 300 # Base: 300 dimensión de los embeddings. \n",
    "HIDDEN_DIM = 128  # Base: 128 dimensión de la capas GRU\n",
    "N_LAYERS = 2  # Base: 2 número de capas.\n",
    "DROPOUT = 0.25 # Base: 0.25\n",
    "BIDIRECTIONAL = True #False --> True\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "\n",
    "model=GENERAL_NER_RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM,\n",
    "                         N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX, \"GRU\")\n",
    "model_name=\"Modelo 2\"\n",
    "model_n_epochs = 5\n",
    "model_loss = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "model_optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-22T16:07:45.755561Z",
     "start_time": "2020-06-22T16:07:45.751571Z"
    },
    "colab_type": "text",
    "id": "Zpy3p7YaaSHT"
   },
   "source": [
    "---------------\n",
    "\n",
    "\n",
    "### Modelo 3\n",
    "\n",
    "Para el modelo 3 se decidió algo distinto, en vez de utilizar una RNN, se decidió utilizar una red convolucional o CNN. Las redes convolucionales son un tipo de red neuronal que se define en base a darle un peso a cada palabra o n-grama, y luego juntarlos todos, luego en base a un criterio se escoge el mejor valor por columna, ya sea por promedio o maximizando. Esto se hace con el proposito de darle más peso a ciertas palabras.\n",
    "\n",
    "Para esto se definieron 1 capa de convolución, con una función de activación RELU, y una capa de pooling con max pooling.\n",
    "Para el embedding se decidió 300, y que fuera bidireccional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:25:51.733572Z",
     "start_time": "2020-06-23T22:25:51.730580Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "_w0CFjA8aSHU"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 150 # dimensión de los embeddings. 100--> 120 (Ext_embedding = 300)\n",
    "HIDDEN_DIM = 128  # dimensión de la capas LSTM \n",
    "N_LAYERS = 2  # número de capas.\n",
    "DROPOUT = 0.25\n",
    "BIDIRECTIONAL = True #False --> True\n",
    "TAG_PAD_IDX = NER_TAGS.vocab.stoi[NER_TAGS.pad_token]\n",
    "\n",
    "model=GENERAL_NER_CNN(INPUT_DIM,EMBEDDING_DIM,HIDDEN_DIM,OUTPUT_DIM,N_LAYERS,DROPOUT,PAD_IDX)\n",
    "model_name=\"Modelo 3\"\n",
    "model_n_epochs = 5\n",
    "model_loss = nn.CrossEntropyLoss(ignore_index = TAG_PAD_IDX)\n",
    "model_optimizer = optim.Adam(model.parameters()) #Probando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xlq48WjiW6U"
   },
   "source": [
    "### Experimentos\n",
    "\n",
    "La seccion de Experimentos puede definirse en dos partes: primero los experimentos que se hicieron con el baseline antes de definir los modelos para definir los parametros, y la segunda parte que corresponden a los experimentos con los modelos bien definidos.\n",
    "\n",
    "#### Experimentos Preliminares.\n",
    "\n",
    "Los experimentos se hicieron con el proposito de ver el peso que tiene cada parametro, y así considerlo al escribir los modelos de redes neuronales. Se usó una metodología con el proposito de evitar hacer todas las combinaciones de parametros. Esta es que: primero definimos un parametro que vamos a cambiar, si este da una mejora respecto al resultado anterior se cambia y aceptamos el cambio, sino pasamos al siguiente parametro.\n",
    "\n",
    "\n",
    "Para el baseline nos dió los siguientes resultados:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.220</th>\n",
    "    <th>0.59</th>\n",
    "    <th>0.64</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "\n",
    "\n",
    "Entonces, se escoge el primer parametro: los embeddings, se cambia el valor base de 100 a 120 embeddings, y de 100 a 140 Se obtuvieron los siguientes resultados:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.213</th>\n",
    "    <th>0.58</th>\n",
    "    <th>0.64</th>\n",
    "    <th>0.58</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.215</th>\n",
    "    <th>0.57</th>\n",
    "    <th>0.63</th>\n",
    "    <th>0.57</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Podemos ver que las dimensiones del embedding afectan moderadamente a las prediciones, resultando en una función de Loss mas baja.\n",
    "\n",
    "\n",
    "Escogemos el siguiente parametro las epochs, cambiamos el valor de 10 a 14. asumiendo los embeddings. Se obtuvieron los siguientes resultados:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.217</th>\n",
    "    <th>0.58</th>\n",
    "    <th>0.64</th>\n",
    "    <th>0.58</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Se puede ver que no afecta considerablemente las puntuaciones, respecto al valor anterior, dado que la iteración que minimiza la loss mayoritariamente se encuentra dentro del rango de 2 a 5 epochs.\n",
    "\n",
    "Escogemos otro parametro, cambiamos la red a una red bidireccional, asumiendo los embeddings. Aqui se tienen los resultados:\n",
    "\n",
    "<table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.184</th>\n",
    "    <th>0.59</th>\n",
    "    <th>0.66</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "\n",
    "</table>\n",
    "\n",
    "Aquí se nota una mejoría considerable respecto a los valores previos, bajando el valor de Loss a menos de 0.200. Por lo que se puede ver que la bidireccionalidad tiene un peso considerable en el rendimiento de la red.\n",
    "\n",
    "Cambiando la cantidad de caps ocultas el resultado tampoco cambia mucho, pero a la red no le perjudica tener más capas, mantienendo los mismos valores con 2, 3 y 4 capas.\n",
    "\n",
    "Respecto a la función de Loss, la funcion de Cross Entropy Loss es la que presenta los mejores resultados, los otros de Loss muy altas para considerarse.\n",
    "Lo mismo con el optimizador Adam, al cambiar de optimizador los resultados empeoraban por lo que se decidió mantener el optimizador para todos los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fo2r4q6aJSaf"
   },
   "source": [
    "\n",
    "### LSTM\n",
    "Parámetros base:\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "  <th>EMBEDDING_DIM</th>\n",
    "  <th>HIDDEN_DIM</th>\n",
    "  <th>N_LAYERS</th>\n",
    "  <th>DROPOUT</th>\n",
    "  <th>BIDIRECTIONAL</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>200</th>\n",
    "    <th>250</th>\n",
    "    <th>5</th>\n",
    "    <th>0.25</th>\n",
    "    <th>True</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Resultados parámetros base:\n",
    "    <table style=\"width:100%\">\n",
    "  <tr> \n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.203</th>\n",
    "    <th>0.62</th>\n",
    "    <th>0.66</th>\n",
    "    <th>0.64</th>\n",
    "  </tr>\n",
    "</table>\n",
    "  - Dimensión de Embeddings: $200 \\to 100$  \n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.236</th>\n",
    "    <th>0.53</th>\n",
    "    <th>0.58</th>\n",
    "    <th>0.56</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Embeddings: $200 \\to 300$ \n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.238</th>\n",
    "    <th>0.53</th>\n",
    "    <th>0.58</th>\n",
    "    <th>0.56</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Capa Oculta: $250 \\to 150$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.237</th>\n",
    "    <th>0.55</th>\n",
    "    <th>0.60</th>\n",
    "    <th>0.56</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Capa Oculta: $250 \\to 350$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.695</th>\n",
    "    <th>0.08</th>\n",
    "    <th>0.23</th>\n",
    "    <th>0.06</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "\n",
    "  </table>\n",
    "  - Layers: $5 \\to 1$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.185</th>\n",
    "    <th>0.63</th>\n",
    "    <th>0.69</th>\n",
    "    <th>0.62</th>\n",
    "  </tr>\n",
    "</table>\n",
    "  - Layers: $5 \\to 8$ \n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.249</th>\n",
    "    <th>0.48</th>\n",
    "    <th>0.54</th>\n",
    "    <th>0.50</th>\n",
    "  </tr>\n",
    "</table>\n",
    "  - Dropout: $25\\% \\to 10\\%$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.</th>\n",
    "    <th>0.</th>\n",
    "    <th>0.</th>\n",
    "    <th>0.</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dropout:  $25\\% \\to 50\\%$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.303</th>\n",
    "    <th>0.59</th>\n",
    "    <th>0.64</th>\n",
    "    <th>0.61</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "</table>\n",
    "  - Bi Directional: $\\to$ False\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.226</th>\n",
    "    <th>0.57</th>\n",
    "    <th>0.61</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "</table>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KmUyGsaLdopt"
   },
   "source": [
    "[Comentarios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9Fw9oidCKOI"
   },
   "source": [
    "### GRU:\n",
    "\n",
    "Parámetros base:\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "  <th>EMBEDDING_DIM</th>\n",
    "  <th>HIDDEN_DIM</th>\n",
    "  <th>N_LAYERS</th>\n",
    "  <th>DROPOUT</th>\n",
    "  <th>BIDIRECTIONAL</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>300</th>\n",
    "    <th>128</th>\n",
    "    <th>2</th>\n",
    "    <th>0.25</th>\n",
    "    <th>True</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Resultados parámetros base:\n",
    "    <table style=\"width:100%\">\n",
    "  <tr> \n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.184</th>\n",
    "    <th>0.62</th>\n",
    "    <th>0.68</th>\n",
    "    <th>0.61</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Embeddings: $300 \\to 150$  \n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.183</th>\n",
    "    <th>0.60</th>\n",
    "    <th>0.67</th>\n",
    "    <th>0.60</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Embeddings: $300 \\to 450$ \n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.184</th>\n",
    "    <th>0.61</th>\n",
    "    <th>0.67</th>\n",
    "    <th>0.60</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Capa Oculta: $128 \\to 192$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.193</th>\n",
    "    <th>0.60</th>\n",
    "    <th>0.67</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "  - Dimensión de Capa Oculta: $128 \\to 64$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.180</th>\n",
    "    <th>0.59</th>\n",
    "    <th>0.66</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "  </table>\n",
    "</table>\n",
    "  - Dropout: $\\to 0.10\\%$:\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.179</th> \n",
    "    <th>0.62</th>\n",
    "    <th>0.68</th>\n",
    "    <th>0.61</th>\n",
    "  </tr>\n",
    "</table>\n",
    "  - Dropout: $\\to 0.50\\%$\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.185</th>\n",
    "    <th>0.62</th>\n",
    "    <th>0.68</th>\n",
    "    <th>0.62</th>\n",
    "  </tr>\n",
    "</table>\n",
    "</table>\n",
    "  - Layers: $\\to$ 1\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr> \n",
    "    <th>0.186</th>\n",
    "    <th>0.60</th>\n",
    "    <th>0.66</th>\n",
    "    <th>0.60</th>\n",
    "  </tr>\n",
    "</table>\n",
    "  - Layers: $\\to$ 6\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.216</th>\n",
    "    <th>0.58</th>\n",
    "    <th>0.63</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "</table>\n",
    "</table>\n",
    "  - Bi Directional: $\\to$ False\n",
    "  <table style=\"width:100%\">\n",
    "  <tr>\n",
    "    <th>Val. Loss</th>\n",
    "    <th>Val.  f1</th>\n",
    "    <th>Val. Precision </th>\n",
    "    <th>Val. Recall</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <th>0.211</th>\n",
    "    <th>0.59</th>\n",
    "    <th>0.66</th>\n",
    "    <th>0.59</th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ArCCmfw_dry5"
   },
   "source": [
    "[Comentarios]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_Cthr0sCWds"
   },
   "source": [
    "### CNN:\n",
    "    - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hy3MVf5H0A94"
   },
   "source": [
    "\n",
    "#### Entrenamiento de la red\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:49:02.524817Z",
     "start_time": "2020-06-23T21:47:09.863026Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "iK5lQqpviicf",
    "outputId": "4de8af7d-6b18-40f2-a09a-65472695551b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.284 | Train f1: 0.40 | Train precision: 0.49 | Train recall: 0.37\n",
      "\t Val. Loss: 0.197 |  Val. f1: 0.56 |  Val. precision: 0.64 | Val. recall: 0.55\n",
      "Epoch: 02 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.082 | Train f1: 0.72 | Train precision: 0.76 | Train recall: 0.72\n",
      "\t Val. Loss: 0.184 |  Val. f1: 0.62 |  Val. precision: 0.68 | Val. recall: 0.61\n",
      "Epoch: 03 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.038 | Train f1: 0.85 | Train precision: 0.86 | Train recall: 0.84\n",
      "\t Val. Loss: 0.216 |  Val. f1: 0.61 |  Val. precision: 0.68 | Val. recall: 0.60\n",
      "Epoch: 04 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.024 | Train f1: 0.89 | Train precision: 0.91 | Train recall: 0.89\n",
      "\t Val. Loss: 0.230 |  Val. f1: 0.61 |  Val. precision: 0.68 | Val. recall: 0.61\n",
      "Epoch: 05 | Epoch Time: 0m 10s\n",
      "\tTrain Loss: 0.017 | Train f1: 0.93 | Train precision: 0.93 | Train recall: 0.92\n",
      "\t Val. Loss: 0.239 |  Val. f1: 0.62 |  Val. precision: 0.69 | Val. recall: 0.61\n",
      "FINAL RESULT: Val. Loss: 0.184 |  Val. f1: 0.62 | Val. precision: 0.68 | Val. recall: 0.61\n"
     ]
    }
   ],
   "source": [
    "# Reasignamos y reiniciamos \n",
    "model_name = model_name\n",
    "criterion = model_loss\n",
    "n_epochs = model_n_epochs\n",
    "optimizer=model_optimizer\n",
    "\n",
    "model.apply(init_weights)\n",
    "\n",
    "# Enviamos el modelo y la loss a cuda (en el caso en que esté disponible)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Recuerdo: train_iterator y valid_iterator contienen el dataset dividido en batches.\n",
    "\n",
    "    # Entrenar\n",
    "    train_loss, train_precision, train_recall, train_f1 = train(\n",
    "        model, train_iterator, optimizer, criterion)\n",
    "\n",
    "    # Evaluar (valid = validación)\n",
    "\n",
    "    valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "        model, valid_iterator, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # Si obtuvimos mejores resultados, guardamos este modelo en el almacenamiento (para poder cargarlo luego)\n",
    "    # Si detienen el entrenamiento prematuramente, pueden cargar el modelo en el siguiente recuadro de código.\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), '{}.pt'.format(model_name))\n",
    "    # Si ya no mejoramos el loss de validación, terminamos de entrenar.\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(\n",
    "        f'\\tTrain Loss: {train_loss:.3f} | Train f1: {train_f1:.2f} | Train precision: {train_precision:.2f} | Train recall: {train_recall:.2f}'\n",
    "    )\n",
    "    print(\n",
    "        f'\\t Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} |  Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    "    )\n",
    "\n",
    "# cargar el mejor modelo entrenado.\n",
    "model.load_state_dict(torch.load('{}.pt'.format(model_name)))\n",
    "# Limpiar ram de cuda\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "valid_loss, valid_precision, valid_recall, valid_f1 = evaluate(\n",
    "    model, valid_iterator, criterion)\n",
    "\n",
    "print(\n",
    "    f'FINAL RESULT: Val. Loss: {valid_loss:.3f} |  Val. f1: {valid_f1:.2f} | Val. precision: {valid_precision:.2f} | Val. recall: {valid_recall:.2f}'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kBctQHTh0lxD"
   },
   "source": [
    "#### Evaluamos el set de validación con el modelo final\n",
    "\n",
    "Estos son los resultados de predecir el dataset de evaluación con el *mejor* modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:26:01.788742Z",
     "start_time": "2020-06-23T22:26:00.558829Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "s0gVbP8yiicj",
    "outputId": "a6a746fe-856c-47b7-9249-a4201bd2ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val. Loss: 0.303 |  Val. f1: 0.59 | Val. precision: 0.64 | Val. recall: 0.61\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uF1ysw_Kw6zz"
   },
   "source": [
    "\n",
    "### Predecir datos para la competencia\n",
    "\n",
    "Ahora, a partir de los datos de **test** y nuestro modelo entrenado, predeciremos las etiquetas que serán evaluadas en la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:31:56.776563Z",
     "start_time": "2020-06-23T22:31:39.654525Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1RBs3UU4wLk3"
   },
   "outputs": [],
   "source": [
    "def predict_labels(model, iterator, criterion, fields=fields):\n",
    "\n",
    "    # Extraemos los vocabularios.\n",
    "    text_field = fields[0][1]\n",
    "    nertags_field = fields[1][1]\n",
    "    tags_vocab = nertags_field.vocab.itos\n",
    "    words_vocab = text_field.vocab.itos\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for batch in iterator:\n",
    "\n",
    "            text_batch = batch.text\n",
    "            text_batch = torch.transpose(text_batch, 0, 1).tolist()\n",
    "\n",
    "            # Predecir los tags de las sentences del batch\n",
    "            predictions_batch = model(batch.text)\n",
    "            predictions_batch = torch.transpose(predictions_batch, 0, 1)\n",
    "\n",
    "            # por cada oración predicha:\n",
    "            for sentence, sentence_prediction in zip(text_batch,\n",
    "                                                     predictions_batch):\n",
    "                for word_idx, word_predictions in zip(sentence,\n",
    "                                                      sentence_prediction):\n",
    "                    # Obtener el indice del tag con la probabilidad mas alta.\n",
    "                    argmax_index = word_predictions.topk(1)[1]\n",
    "\n",
    "                    current_tag = tags_vocab[argmax_index]\n",
    "                    # Obtenemos la palabra\n",
    "                    current_word = words_vocab[word_idx]\n",
    "\n",
    "                    if current_word != '<pad>':\n",
    "                        predictions.append([current_word, current_tag])\n",
    "\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "predictions = predict_labels(model, test_iterator, criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YwQp1Ru8Oht8"
   },
   "source": [
    "### Generar el archivo para la submission\n",
    "\n",
    "No hay problema si aparecen unk en la salida. Estos no son relevantes para evaluarlos, usamos solo los tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T22:33:41.845955Z",
     "start_time": "2020-06-23T22:33:41.731717Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "RPfZkjJGkWyq"
   },
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "if (os.path.isfile('./predictions.zip')):\n",
    "    os.remove('./predictions.zip')\n",
    "\n",
    "if (not os.path.isdir('./predictions')):\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "else:\n",
    "    # Eliminar predicciones anteriores:\n",
    "    shutil.rmtree('./predictions')\n",
    "    os.mkdir('./predictions')\n",
    "\n",
    "f = open('predictions/predictions.txt', 'w')\n",
    "for word, tag in predictions:\n",
    "    f.write(word + ' ' + tag + '\\n')\n",
    "f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "a = shutil.make_archive('predictions', 'zip', './predictions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-23T21:49:19.575711Z",
     "start_time": "2020-06-23T21:49:19.100486Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "k2PqvJAmTFWR",
    "outputId": "bbed66e0-748d-4763-dd25-9a12182c337f"
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "    async function download(id, filename, size) {\n",
       "      if (!google.colab.kernel.accessAllowed) {\n",
       "        return;\n",
       "      }\n",
       "      const div = document.createElement('div');\n",
       "      const label = document.createElement('label');\n",
       "      label.textContent = `Downloading \"${filename}\": `;\n",
       "      div.appendChild(label);\n",
       "      const progress = document.createElement('progress');\n",
       "      progress.max = size;\n",
       "      div.appendChild(progress);\n",
       "      document.body.appendChild(div);\n",
       "\n",
       "      const buffers = [];\n",
       "      let downloaded = 0;\n",
       "\n",
       "      const channel = await google.colab.kernel.comms.open(id);\n",
       "      // Send a message to notify the kernel that we're ready.\n",
       "      channel.send({})\n",
       "\n",
       "      for await (const message of channel.messages) {\n",
       "        // Send a message to notify the kernel that we're ready.\n",
       "        channel.send({})\n",
       "        if (message.buffers) {\n",
       "          for (const buffer of message.buffers) {\n",
       "            buffers.push(buffer);\n",
       "            downloaded += buffer.byteLength;\n",
       "            progress.value = downloaded;\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
       "      const a = document.createElement('a');\n",
       "      a.href = window.URL.createObjectURL(blob);\n",
       "      a.download = filename;\n",
       "      div.appendChild(a);\n",
       "      a.click();\n",
       "      div.remove();\n",
       "    }\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "download(\"download_7442e438-fe87-47c8-8932-5fb0e1e2c295\", \"predictions.zip\", 109819)"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A veces no funciona a la primera. Ejecutar mas de una vez para obtener el archivo...\n",
    "from google.colab import files\n",
    "files.download('predictions.zip')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LZEWJXrNaSIf"
   },
   "source": [
    "## Conclusiones\n",
    "\n",
    "\n",
    "\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Tarea_2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
